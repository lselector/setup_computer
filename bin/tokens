#!/bin/bash
# Function to estimate tokens in a text file using awk
estimate_tokens() {
    local file=$1
    if [ ! -f "$file" ]; then
        echo "Error: File '$file' not found." >&2
        return 1
    fi
    
    # Use awk to process the file in a single pass
    local estimate=$(awk '
    BEGIN {
        word_count = 0;
        char_count = 0;
        punct_count = 0;
    }
    {
        # Count words
        word_count += NF;
        
        # Count characters (including newlines)
        char_count += length($0) + 1;
        
        # Count punctuation
        for (i = 1; i <= length($0); i++) {
            c = substr($0, i, 1);
            if (c ~ /[.,!?;:()\[\]{}"\047]/)
                punct_count++;
        }
    }
    END {
        # Calculate estimates
        basic_estimate = word_count + (punct_count / 2);
        char_based_estimate = char_count / 4;
        
        # Average both methods and round to nearest integer
        printf("%d\n", int((basic_estimate + char_based_estimate) / 2 + 0.5));
    }
    ' "$file")
    
    echo "$estimate"
}

# Main function
main() {
    if [ $# -eq 0 ]; then
        echo "Usage: $0 <file1> [file2] [file3] ..." >&2
        exit 1
    fi
    
    local total_tokens=0
    local file_count=0
    
    # Process each file
    for file in "$@"; do
        if [ -f "$file" ]; then
            tokens=$(estimate_tokens "$file")
            if [ $? -eq 0 ]; then
                printf "%7d : %s\n" "$tokens" "$file"
                total_tokens=$((total_tokens + tokens))
                file_count=$((file_count + 1))
            fi
        else
            echo "Warning: '$file' is not a file, skipping." >&2
        fi
    done
    
    # Print summary
    if [ $file_count -gt 1 ]; then
        echo "------------------------"
        printf "%7d : TOTAL (across %d files)\n" "$total_tokens" "$file_count"
    fi
}

# Execute main function with all arguments
main "$@"

